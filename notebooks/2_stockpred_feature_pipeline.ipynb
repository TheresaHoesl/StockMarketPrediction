{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "# Tradable Price Feature Pipeline Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from functions import util\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import pytz\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "### Login to Hopsworks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-06 12:24:11,433 INFO: Initializing external client\n",
      "2025-01-06 12:24:11,436 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-06 12:24:13,369 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1205424\n",
      "File successfully found at the path: ../data/alphavantage-api-key.txt\n"
     ]
    }
   ],
   "source": [
    "# If you haven't set the env variable 'HOPSWORKS_API_KEY', then uncomment the next line and enter your API key\n",
    "with open('../data/hopsworks-api-key.txt', 'r') as file:\n",
    "    os.environ[\"HOPSWORKS_API_KEY\"] = file.read().rstrip()\n",
    "\n",
    "project = hopsworks.login(project = 'StockPrediction', api_key_value=os.environ[\"HOPSWORKS_API_KEY\"])\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "api_key_file = '../data/alphavantage-api-key.txt'\n",
    "util.check_file_path(api_key_file)\n",
    "\n",
    "with open(api_key_file, 'r') as file:\n",
    "    ALPHAVANTAGE_API_KEY = file.read().rstrip()\n",
    "\n",
    "secrets_api = hopsworks.get_secrets_api()\n",
    "try:\n",
    "    secrets_api.create_secret('AV_API_KEY', ALPHAVANTAGE_API_KEY)\n",
    "except hopsworks.RestAPIError:\n",
    "    ALPHAVANTAGE_API_KEY = secrets_api.get_secret(\"AV_API_KEY\").value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### Get references to the Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "SPOT_fg = fs.get_feature_group(\n",
    "    name='spot',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "GOOGL_fg = fs.get_feature_group(\n",
    "    name='googl',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "BTC_fg = fs.get_feature_group(\n",
    "    name='btc',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "SandP_fg = fs.get_feature_group(\n",
    "    name='sandp',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "Sent_SPOT_fg = fs.get_feature_group(\n",
    "    name='spotify_sentiment',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "Sent_GOOGL_fg = fs.get_feature_group(\n",
    "    name='google_sentiment',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "Sent_BTC_fg = fs.get_feature_group(\n",
    "    name='bitcoin_sentiment',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "### Retrieve Today's Tradable Price data from AV API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Meta Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# spot_today = util.get_stock_price(\"SPOT\", ALPHAVANTAGE_API_KEY)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# googl_today = util.get_stock_price(\"GOOGL\", ALPHAVANTAGE_API_KEY)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m btc_today \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_crypto_price\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBTC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mALPHAVANTAGE_API_KEY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m sandp_today \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mget_stock_price(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIVV\u001b[39m\u001b[38;5;124m\"\u001b[39m, ALPHAVANTAGE_API_KEY)\n\u001b[0;32m      5\u001b[0m sent_spot_today \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mget_sentiment_score(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPOT\u001b[39m\u001b[38;5;124m\"\u001b[39m, ALPHAVANTAGE_API_KEY)\n",
      "File \u001b[1;32mc:\\Users\\there\\OneDrive\\Desktop\\Master\\ScalableML\\StockMarketPrediction\\notebooks\\functions\\util.py:68\u001b[0m, in \u001b[0;36mget_crypto_price\u001b[1;34m(symbol, ALPHAVANTAGE_API_KEY)\u001b[0m\n\u001b[0;32m     65\u001b[0m data \u001b[38;5;241m=\u001b[39m trigger_request(url)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Extract the latest date\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m latest_date \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMeta Data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6. Last Refreshed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     69\u001b[0m latest_date_only \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(latest_date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdate()\n\u001b[0;32m     70\u001b[0m latest_close_price \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime Series (Digital Currency Daily)\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mstr\u001b[39m(latest_date_only)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4. close\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Meta Data'"
     ]
    }
   ],
   "source": [
    "spot_today = util.get_stock_price(\"SPOT\", ALPHAVANTAGE_API_KEY)\n",
    "googl_today = util.get_stock_price(\"GOOGL\", ALPHAVANTAGE_API_KEY)\n",
    "btc_today = util.get_crypto_price(\"BTC\", ALPHAVANTAGE_API_KEY)\n",
    "sandp_today = util.get_stock_price(\"IVV\", ALPHAVANTAGE_API_KEY)\n",
    "sent_spot_today = util.get_sentiment_score(\"SPOT\", ALPHAVANTAGE_API_KEY)\n",
    "sent_googl_today = util.get_sentiment_score(\"GOOG\", ALPHAVANTAGE_API_KEY)\n",
    "sent_btc_today = util.get_sentiment_score(\"CRYPTO:BTC\", ALPHAVANTAGE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Uploading new data to the Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eee28f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-06 12:07:13,023 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1205424/fs/1194062/fg/1393604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: spot_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1205424/jobs/named/spot_1_offline_fg_materialization/executions\n",
      "2025-01-06 12:07:43,438 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1205424/fs/1194062/fg/1394635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 01:21 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: googl_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1205424/jobs/named/googl_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "ename": "FeatureStoreException",
     "evalue": "Features are not compatible with Feature Group schema: \n - timestamp (expected type: 'timestamp', derived from input: 'date') has the wrong type.\nNote that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureStoreException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m SPOT_fg\u001b[38;5;241m.\u001b[39minsert(spot_today)\n\u001b[0;32m      3\u001b[0m GOOGL_fg\u001b[38;5;241m.\u001b[39minsert(googl_today)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mBTC_fg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbtc_today\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m SandP_fg\u001b[38;5;241m.\u001b[39minsert(sandp_today)\n\u001b[0;32m      6\u001b[0m Sent_SPOT_fg\u001b[38;5;241m.\u001b[39minsert(sent_spot_today)\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\feature_group.py:2940\u001b[0m, in \u001b[0;36mFeatureGroup.insert\u001b[1;34m(self, features, overwrite, operation, storage, write_options, validation_options, wait)\u001b[0m\n\u001b[0;32m   2937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offline_backfill_every_hr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2938\u001b[0m     write_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffline_backfill_every_hr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offline_backfill_every_hr\n\u001b[1;32m-> 2940\u001b[0m job, ge_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_group_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2941\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2944\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_report\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mget_type()\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[0;32m   2951\u001b[0m     \u001b[38;5;66;03m# Also, only compute statistics if stream is False.\u001b[39;00m\n\u001b[0;32m   2952\u001b[0m     \u001b[38;5;66;03m# if True, the backfill job has not been triggered and the data has not been inserted (it's in Kafka)\u001b[39;00m\n\u001b[0;32m   2953\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_statistics()\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\core\\feature_group_engine.py:176\u001b[0m, in \u001b[0;36mFeatureGroupEngine.insert\u001b[1;34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_feature_group_metadata(\n\u001b[0;32m    172\u001b[0m         feature_group, dataframe_features, write_options\n\u001b[0;32m    173\u001b[0m     )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# else, just verify that feature group schema matches user-provided dataframe\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_verify_schema_compatibility\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe_features\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# ge validation on python and non stream feature groups on spark\u001b[39;00m\n\u001b[0;32m    181\u001b[0m ge_report \u001b[38;5;241m=\u001b[39m feature_group\u001b[38;5;241m.\u001b[39m_great_expectation_engine\u001b[38;5;241m.\u001b[39mvalidate(\n\u001b[0;32m    182\u001b[0m     feature_group\u001b[38;5;241m=\u001b[39mfeature_group,\n\u001b[0;32m    183\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mfeature_dataframe,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m     ge_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    187\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\there\\anaconda3\\envs\\airquality\\lib\\site-packages\\hsfs\\core\\feature_group_base_engine.py:171\u001b[0m, in \u001b[0;36mFeatureGroupBaseEngine._verify_schema_compatibility\u001b[1;34m(self, feature_group_features, dataframe_features)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# raise exception if any errors were found.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(err) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures are not compatible with Feature Group schema: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m err])\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote that feature (or column) names are case insensitive and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspaces are automatically replaced with underscores.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n",
      "\u001b[1;31mFeatureStoreException\u001b[0m: Features are not compatible with Feature Group schema: \n - timestamp (expected type: 'timestamp', derived from input: 'date') has the wrong type.\nNote that feature (or column) names are case insensitive and spaces are automatically replaced with underscores."
     ]
    }
   ],
   "source": [
    "# Insert new data\n",
    "\n",
    "SPOT_fg.insert(spot_today)\n",
    "GOOGL_fg.insert(googl_today)\n",
    "BTC_fg.insert(btc_today)\n",
    "SandP_fg.insert(sandp_today)\n",
    "Sent_SPOT_fg.insert(sent_spot_today)\n",
    "Sent_GOOGL_fg.insert(sent_googl_today)\n",
    "Sent_BTC_fg.insert(sent_btc_today)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airquality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
